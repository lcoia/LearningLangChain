{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XTKyJabSO0C"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain-groq langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a-llm.py\n",
        "# Note: using a free Groq model instead of paid OpenAI\n",
        "from langchain_groq.chat_models import ChatGroq"
      ],
      "metadata": {
        "id": "YzkMMr7TTbQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store your API keys in Google Colab Secrets\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "A24ZZp2MdcAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatGroq(model=\"llama3-70b-8192\", api_key=userdata.get('GROQ_API_KEY'))"
      ],
      "metadata": {
        "id": "i7-dFN6RT1Nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.invoke(\"The sky is\")\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAbBgBWFhjI0",
        "outputId": "4eda0dbe-2de2-4fb9-e90c-4d11c45a40d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...blue!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# b-chat.py\n",
        "from langchain_core.messages import HumanMessage\n",
        "prompt = [HumanMessage(\"What is the capital of France?\")]"
      ],
      "metadata": {
        "id": "iV90uSwBiL8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.invoke(prompt)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jyAxflaiv4u",
        "outputId": "daea0a50-0168-4875-a278-477e8f2f3bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of France is Paris.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# c-system.py\n",
        "from langchain_core.messages import SystemMessage\n",
        "\n",
        "system_msg = SystemMessage(\n",
        "    \"You are a helpful assistant that responds to questions with three exclamation marks.\"\n",
        ")\n",
        "human_msg = HumanMessage(\"What is the capital of France?\")\n",
        "\n",
        "response = model.invoke([system_msg, human_msg])\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tF8aRVwri2Lp",
        "outputId": "32a5e4f1-b7fd-4a09-9da3-be86b6730841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paris!!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0JRS98FhjJ3M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}