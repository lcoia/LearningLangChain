{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjmeX/4pJ0ZdnvWtOrSELe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lcoia/LearningLangChain/blob/main/Chapter2/Chapter2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZaKstluTsML"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain-groq langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "a-text-loader.py\n",
        "\n",
        "Note: Files are not saved after the Colab runtime terminates.\n",
        "Load the sample text file, ECB_policymakers.txt, from the sample_data folder.\n",
        "Please upload the text file, ECB_policymakers.txt, from the link below to the sample_data folder.\n",
        "\n",
        "https://drive.google.com/file/d/1pO-DRfmc5KuHIZbD75hffcyAEmICclbL/view?usp=sharing\n",
        "\n",
        "\n",
        "LangChain Loaders\n",
        "https://python.langchain.com/api_reference/community/document_loaders.html\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "loader = TextLoader('./sample_data/ECB_policymakers.txt', encoding=\"utf-8\")\n",
        "docs = loader.load()\n",
        "\n",
        "print(docs)"
      ],
      "metadata": {
        "id": "a5f5khQa1vKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Beautiful Soup is a library that makes it easy to scrape information from web pages.\n",
        "This library is required for the next example.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "!pip install beautifulsoup4"
      ],
      "metadata": {
        "id": "KAE1UZgZ93D0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "b-web-loader.py\n",
        "\n",
        "Load a web page.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "loader = WebBaseLoader('https://www.langchain.com/')\n",
        "docs = loader.load()\n",
        "\n",
        "print(docs)"
      ],
      "metadata": {
        "id": "xwOTUpwf9b8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "pypdf is a PDF library capable of splitting, merging, cropping, and transforming the pages of PDF files.\n",
        "This library is required for the next example.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "neSkUp2uDEAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "c-pdf-loader.py\n",
        "\n",
        "Note: Files are not saved after the Colab runtime terminates.\n",
        "Please upload the PDF file from the link below to the sample_data folder.\n",
        "\n",
        "https://www.babson.edu/media/babson/assets/cutler-center/Introduciton-to-Technical-Analysis.pdf\n",
        "\n",
        "\"\"\"\n",
        "import pprint\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader('./sample_data/Introduciton-to-Technical-Analysis.pdf')\n",
        "pages = loader.load()\n",
        "\n",
        "pprint.pprint(pages)"
      ],
      "metadata": {
        "id": "w-WKwu3v-SsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "d-rec-text-splitter.py\n",
        "\n",
        "Split the document into chunks to fit in the context window of the LLM.\n",
        "\n",
        "LangChain Text Splitters\n",
        "https://python.langchain.com/docs/concepts/text_splitters/\n",
        "\n",
        "\n",
        "Late chunking for better semantic context.\n",
        "https://www.datacamp.com/tutorial/late-chunking\n",
        "https://docs.chonkie.ai/chunkers/overview\n",
        "\n",
        "MTEB Embedding Models (Massive Text Embedding Benchmark)\n",
        "https://modal.com/blog/mteb-leaderboard-article\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "loader = TextLoader('./sample_data/ECB_policymakers.txt', encoding=\"utf-8\")\n",
        "docs = loader.load()\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splitted_docs = splitter.split_documents(docs)\n",
        "\n",
        "pprint.pprint(splitted_docs)\n"
      ],
      "metadata": {
        "id": "hsZ1alqvmi1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "e-rec-text-splitter-code.py\n",
        "\n",
        "Split code languages and Markdown into semantic chunks.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from langchain_text_splitters import (\n",
        "    Language,\n",
        "    RecursiveCharacterTextSplitter,\n",
        ")\n",
        "\n",
        "PYTHON_CODE = \"\"\" def hello_world(): print(\"Hello, World!\") # Call the function hello_world() \"\"\"\n",
        "\n",
        "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
        "    language=Language.PYTHON, chunk_size=50, chunk_overlap=0\n",
        ")\n",
        "\n",
        "python_docs = python_splitter.create_documents([PYTHON_CODE])\n",
        "\n",
        "print(python_docs)"
      ],
      "metadata": {
        "id": "XMhr_743cdpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "g-embeddings.py\n",
        "\n",
        "Generating text embeddings.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from langchain_groq import GroqE\n",
        "\n",
        "model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "embeddings = model.embed_documents([\n",
        "    \"Hi there!\",\n",
        "    \"Oh, hello!\",\n",
        "    \"What's your name?\",\n",
        "    \"My friends call me World\",\n",
        "    \"Hello World!\"\n",
        "])\n",
        "\n",
        "print(embeddings)"
      ],
      "metadata": {
        "id": "TLE9eiTIdHu0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}